{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee3505f-c88d-4880-91a8-f4d2dd9e756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "087ffb29-7e78-49d1-bf37-ab5ae06e439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdp_attn(q, k, v, is_causal, n_embd, n_heads):\n",
    "    nh, hc = n_heads, n_embd // n_heads\n",
    "    q = rearrange(q, 'b t (nh hc) -> b nh t hc', nh=nh, hc=hc)\n",
    "    k = rearrange(k, 'b t (nh hc) -> b nh t hc', nh=nh, hc=hc)\n",
    "    v = rearrange(v, 'b t (nh hc) -> b nh t hc', nh=nh, hc=hc)\n",
    "\n",
    "    attn = F.scaled_dot_product_attention(q, k, v, is_causal=is_causal)\n",
    "    attn = rearrange(attn, 'b nh t hc -> b t (nh hc)')\n",
    "    return attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee30d9f-6756-4d71-9d0a-a99322a3ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttn(nn.Module):\n",
    "    def __init__(self, cfg, is_causal):\n",
    "        super().__init__()\n",
    "        self.n_embd = cfg['n_embd']\n",
    "        self.n_heads = cfg['n_heads']\n",
    "        self.is_causal = is_causal\n",
    "        self.QKV = nn.Linear(self.n_embd, 3*self.n_embd, bias=False)\n",
    "        self.out_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        q, k, v = torch.split(self.QKV(x), self.n_embd, dim=-1)\n",
    "        attn = sdp_attn(q, k, v, self.is_causal, self.n_embd, self.n_heads)\n",
    "        return self.out_proj(attn)\n",
    "\n",
    "\n",
    "class CrossAttn(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.n_embd = cfg['n_embd']\n",
    "        self.n_heads = cfg['n_heads']\n",
    "        self.KV = nn.Linear(self.n_embd, 2*self.n_embd, bias=False)\n",
    "        self.Q = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
    "        self.out_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
    "\n",
    "    def forward(self, x, x_enc):\n",
    "        k, v = torch.split(self.KV(x_enc), self.n_embd, dim=-1)\n",
    "        q = self.Q(x)\n",
    "        attn = sdp_attn(q, k, v, True, self.n_embd, self.n_heads)\n",
    "        return self.out_proj(attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "557793b2-8987-4fe4-8367-61b07aaf8ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embd = 6\n",
    "n_heads = 2\n",
    "cfg = { 'n_embd': n_embd, 'n_heads': n_heads }\n",
    "sa = SelfAttn(cfg, is_causal=True)\n",
    "ca = CrossAttn(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "751fdcd7-99f1-4c6c-b979-d40fcd039e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 6]), torch.Size([1, 5, 6]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 5, n_embd)\n",
    "y = torch.randn(1, 3, n_embd)\n",
    "sa(y).shape, ca(x, y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c39128-46e9-4150-895d-391a56354b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        n_embd = cfg['n_embd']\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd*4, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_embd*4, n_embd, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bc6d758-c330-4a60-a362-8e25de06c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.ln0 = nn.LayerNorm(cfg['n_embd'])\n",
    "        self.sa = SelfAttn(cfg, is_causal=False)\n",
    "        self.ln1 = nn.LayerNorm(cfg['n_embd'])\n",
    "        self.mlp = MLP(cfg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln0(x))\n",
    "        x = x + self.mlp(self.ln1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        n_embd = cfg['n_embd']\n",
    "        self.ln0 = nn.LayerNorm(n_embd)\n",
    "        self.sa = SelfAttn(cfg, is_causal=False)\n",
    "        \n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ca = CrossAttn(cfg)\n",
    "\n",
    "        self.ln2 = nn.LayerNorm(n_embd)        \n",
    "        self.mlp = MLP(cfg)\n",
    "\n",
    "    def forward(self, x, x_enc):\n",
    "        x = x + self.sa(self.ln0(x))\n",
    "        x = x + self.ca(self.ln1(x), x_enc)\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc07aa3c-0635-4155-b4cc-534ad2d07ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_blk = EncoderBlock(cfg)\n",
    "dec_blk = DecoderBlock(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4195a51f-f88c-4786-b34b-28440967dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 5, n_embd)\n",
    "y = torch.randn(1, 3, n_embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc8b2f7b-7ce2-4f44-a3e3-9a94f752a452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 6]), torch.Size([1, 5, 6]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_blk(y).shape, dec_blk(x, y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d641d86-7518-400b-a7b2-9aa9caef0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchify(x, patch_size, pad_val=None):\n",
    "    B, C, H, W = x.shape\n",
    "    pw, ph = patch_size\n",
    "    dy, dx = H % ph, W % pw\n",
    "    if pad_val is not None:  \n",
    "        pad_left, pad_top = dx // 2, dy // 2\n",
    "        pad_right, pad_bot = dx - pad_left, dy - pad_top\n",
    "        x = F.pad(x, (pad_left, pad_right, pad_top, pad_bot), value=pad_val)\n",
    "    else:\n",
    "        assert dx == 0 and dy == 0\n",
    "\n",
    "    H, W = x.shape[-2], x.shape[-1]\n",
    "    # split into patches, then flatten them\n",
    "    x = rearrange(x, 'b c (hs h) (ws w) -> b (hs ws) (h w c)', hs=H//ph, ws=W//pw)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1e6a544c-a295-431f-9ac9-a88010bfbb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0,  1,  2,  3,  4,  5],\n",
      "          [ 6,  7,  8,  9, 10, 11],\n",
      "          [12, 13, 14, 15, 16, 17],\n",
      "          [18, 19, 20, 21, 22, 23]]]])\n",
      "torch.Size([1, 6, 4])\n",
      "tensor([[[ 0,  1,  6,  7],\n",
      "         [ 2,  3,  8,  9],\n",
      "         [ 4,  5, 10, 11],\n",
      "         [12, 13, 18, 19],\n",
      "         [14, 15, 20, 21],\n",
      "         [16, 17, 22, 23]]])\n"
     ]
    }
   ],
   "source": [
    "B, C, H, W = 1, 1, 4, 6\n",
    "x = torch.arange(B*C*H*W).view(B,C,H,W)\n",
    "print(x)\n",
    "x = patchify(x, (2, 2))\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05593e05-bbae-45bd-ad71-cbd58bc6b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        channels = cfg['channels']\n",
    "        pw, ph = cfg['patch_size']\n",
    "        n_ctx = cfg['n_ctx']\n",
    "        n_embd = cfg['n_embd']\n",
    "        n_blocks = cfg['n_blocks']\n",
    "        \n",
    "        self.patch_size = (pw, ph)\n",
    "        self.pad_value = cfg.get('pad_value', None)\n",
    "\n",
    "        self.embd = nn.Embedding(n_ctx, n_embd)\n",
    "        self.project_patch = nn.Linear(pw*ph*channels, n_embd, bias=False)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            EncoderBlock(cfg) for _ in range(n_blocks)\n",
    "        ])\n",
    "        self.ln_out = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = patchify(x, self.patch_size, self.pad_value)\n",
    "        x = self.project_patch(x)\n",
    "        \n",
    "        device = next(self.parameters()).device\n",
    "        B, T, E = x.shape\n",
    "        x = x + self.embd(torch.arange(T, device=device))\n",
    "            \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return self.ln_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19d2ea0a-cd23-45e9-b259-f0af73156fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1044"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_cfg = {\n",
    "    'n_blocks': 2,\n",
    "    'n_ctx': 16,\n",
    "    'channels': 1,\n",
    "    'patch_size': (2, 2),\n",
    "    'n_embd': 6,\n",
    "    'n_heads': 2\n",
    "}\n",
    "encoder = Encoder(enc_cfg)\n",
    "sum(p.numel() for p in encoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a778a2e-3026-467d-b5d7-86b409ce44fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 6])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, enc_cfg['channels'], 2, 4)\n",
    "encoder(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d8a3e605-ed42-4817-a438-c10061e9f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TiedLinear(nn.Module):\n",
    "    def __init__(self, w):\n",
    "        super().__init__()\n",
    "        self.w = w\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.linear(x, self.w, bias=None)\n",
    "        \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        n_ctx, n_vocab = cfg['n_ctx'], cfg['n_vocab']\n",
    "        n_blocks, n_embd = cfg['n_blocks'], cfg['n_embd']\n",
    "\n",
    "        self.embd_tok = nn.Embedding(n_vocab, n_embd)\n",
    "        self.embd_pos = nn.Embedding(n_ctx, n_embd)\n",
    "        \n",
    "        self.blocks = nn.ModuleList([\n",
    "            DecoderBlock(cfg) for _ in range(n_blocks)\n",
    "        ])\n",
    "        self.ln_out = nn.LayerNorm(n_embd)\n",
    "        self.head = TiedLinear(self.embd_tok.weight)\n",
    "\n",
    "    def forward(self, x, x_enc):\n",
    "        B, T = x.shape\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        tok_embd = self.embd_tok(x)\n",
    "        pos_embd = self.embd_pos(torch.arange(T, device=device))\n",
    "        x = tok_embd + pos_embd\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x, x_enc)\n",
    "\n",
    "        x = self.ln_out(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3d82c34-72e1-4577-ba7b-3c6a9f643d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1374"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = {\n",
    "    'n_ctx': 16,\n",
    "    'n_vocab': 7,\n",
    "    'n_blocks': 2,\n",
    "    'n_embd': 6,\n",
    "    'n_heads': 2,\n",
    "}\n",
    "decoder = Decoder(cfg)\n",
    "sum(p.numel() for p in decoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "09947bc5-f7ec-409f-80fd-c44eec5fdc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 7])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(cfg['n_vocab'], size=(1,5))\n",
    "y = torch.randn(1, 3, cfg['n_embd'])\n",
    "decoder(x, y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "32b30926-03af-4c32-a05a-362ce2cf08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out, ch_mid=None):\n",
    "        super().__init__()\n",
    "        if ch_mid is None:\n",
    "            ch_mid = ch_out\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_mid, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(ch_mid),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(ch_mid, ch_out, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        ch_in = cfg['ch_in']\n",
    "        fts, ch_out = cfg['init_filters'], cfg['ch_out']\n",
    "        n_layers = cfg['n_layers']\n",
    "\n",
    "        self.bn_in = nn.BatchNorm2d(ch_in) # input normalization for the lazy\n",
    "        self.conv_in = nn.Conv2d(ch_in, fts, 3, 1, 1, bias=False)\n",
    "        self.bn0 = nn.BatchNorm2d(fts)\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            DoubleConv(2**k * fts, 2**(k+1) * fts) for k in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        self.conv_out = nn.Conv2d(2**n_layers * fts, ch_out, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn_in(x)\n",
    "        x = F.relu(self.bn0(self.conv_in(x)))\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        return self.conv_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "05e082a2-2d33-4bd7-9b85-4ac96e1b22d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23038"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_cfg = {\n",
    "    'ch_in': 1,\n",
    "    'n_layers': 3,\n",
    "    'init_filters': 4,\n",
    "    'ch_out': 16\n",
    "}\n",
    "cnn = CNN(cnn_cfg)\n",
    "sum(p.numel() for p in cnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18b65a90-f4ee-460b-8b9e-9dcd2b8e76fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 4, 8])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 32, 64)\n",
    "x = cnn(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f2032e83-91b4-4e41-9781-8d33193e8cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 64])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchify(x, (2, 2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b01f6ee3-0f5b-4a86-86fa-ab2db2c1417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCRNet(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.backbone = CNN(cfg['backbone'])\n",
    "        self.encoder = Encoder(cfg['encoder'])\n",
    "        self.decoder = Decoder(cfg['decoder'])\n",
    "\n",
    "    def forward(self, x_im, x_tok):\n",
    "        vis_fts = self.backbone(x_im)\n",
    "        x_enc = self.encoder(vis_fts)\n",
    "        x = self.decoder(x_tok, x_enc)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a306f9da-4aeb-419f-b06e-d418e1b6ac4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "551850"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = {\n",
    "    'backbone': {\n",
    "        'ch_in': 1,\n",
    "        'n_layers': 3,\n",
    "        'init_filters': 8,\n",
    "        'ch_out': 16\n",
    "    },\n",
    "    'encoder': {\n",
    "        'n_blocks': 4,\n",
    "        'n_ctx': 16,\n",
    "        'channels': 16,\n",
    "        'patch_size': (2, 2),\n",
    "        'n_embd': 64,\n",
    "        'n_heads': 4\n",
    "    },\n",
    "    'decoder': {\n",
    "        'n_ctx': 16,\n",
    "        'n_vocab': 28,\n",
    "        'n_blocks': 4,\n",
    "        'n_embd': 64,\n",
    "        'n_heads': 4,\n",
    "    }\n",
    "}\n",
    "net = OCRNet(cfg)\n",
    "sum(p.numel() for p in net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd5126b4-bd74-4fcd-9270-c0f605784548",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_im = torch.randn(1, 1, 32, 128)\n",
    "x_tok = torch.randint(28, (1, 3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0ebc7081-e8a9-492c-9de5-7f53b2f6fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = net(x_im, x_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a1e0f913-28cd-48ac-b125-336850e2801e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 28])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97fc14d-4c6b-4423-908a-219a9101c5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
